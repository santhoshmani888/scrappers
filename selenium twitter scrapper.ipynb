{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"Desktop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Crawling for #mondaymotivation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50/50 complete..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Grabbed 981 tweets from mondaymotivation...\n",
      ">> Crawling for #bestfriends\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50/50 complete..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Grabbed 1959 tweets from bestfriends...\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "firefox_profile = webdriver.FirefoxProfile()\n",
    "firefox_profile.set_preference('permissions.default.stylesheet', 2)\n",
    "firefox_profile.set_preference('permissions.default.image', 2)\n",
    "firefox_profile.set_preference('dom.ipc.plugins.enabled.libflashplayer.so', 'false')\n",
    "# create driver\n",
    "driver = webdriver.Firefox(firefox_profile=firefox_profile)\n",
    "\n",
    "base_url = lambda hashtag : 'https://twitter.com/hashtag/{}?src=hash'.format(hashtag)\n",
    "res=[]\n",
    "hasht=[]\n",
    "def get_soup(url):\n",
    "    return BeautifulSoup( requests.get(url).content, 'lxml')\n",
    "\n",
    "def crawl_page(url, n):\n",
    "    # open url\n",
    "    driver.get(url)\n",
    "    # wait for page to load\n",
    "    driver.implicitly_wait(15)\n",
    "    # scroll for n seconds\n",
    "    for i in range(n):\n",
    "        elem = driver.find_element_by_tag_name('a')\n",
    "        elem.send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "        sys.stderr.write('\\r{0}/{1} complete...'.format(i+1,n))\n",
    "    # gather list items\n",
    "    list_items = driver.find_elements_by_tag_name('ol')\n",
    "    # get soup\n",
    "    if list_items:\n",
    "        soup = BeautifulSoup(list_items[0].get_attribute('innerHTML'),'lxml')\n",
    "        return soup\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def extract_tweet_ids(soup,hashtag):\n",
    "    h=hashtag\n",
    "    for i in soup.find_all('li', {\"data-item-type\":\"tweet\"}):\n",
    "        try:\n",
    "            text = (i.p.get_text())\n",
    "        #print(text)\n",
    "            res.append(text)\n",
    "            hasht.append(h)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "            \n",
    "        \n",
    "            \n",
    "\n",
    "    return res,hasht\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    hashtags = ['mondaymotivation','bestfriends']\n",
    "    n=50\n",
    "    tweet_ids,hashstore=[],[]\n",
    "    hashlist=[]\n",
    "    for hashtag in hashtags:\n",
    "        print('>> Crawling for #{}'.format(hashtag))\n",
    "        soup = crawl_page(base_url(hashtag), n)\n",
    "        if soup:\n",
    "            tweet_ids,hashstore = extract_tweet_ids(soup,hashtag)\n",
    "        \n",
    "            print('>> Grabbed {0} tweets from {1}...'.format(len(tweet_ids),hashtag))\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    t=[[i] for i in tweet_ids]\n",
    "    df =  pd.DataFrame(t)\n",
    "    df['hashtags'] = pd.Series(hashstore).values\n",
    "    \n",
    "    df.to_csv('outsample.csv', sep=',', header=['tweet_text','hastag'], index=None)\n",
    "\n",
    "    \n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\santh_000'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
